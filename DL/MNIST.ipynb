{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40154c99",
   "metadata": {},
   "source": [
    "# 개요\n",
    " > **손으로 직접쓴 숫자(필기체 숫자)로 이루어진 데이터 셋**\n",
    " - 딥러닝을 배울때 반드시 거쳐야 하는 'Hello, World' 같은 존재\n",
    " - 0~9까지 숫자 이미지로 구성, 6만개 트레이닝 데이터, 1만개 테스트 데이터로 이루어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad9bbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bca1e8",
   "metadata": {},
   "source": [
    "# MNIST 다운\n",
    "1. csv file(, 구분)\n",
    " - Training data : http://www.pjreddie.com.media/files/mnist_train.csv\n",
    " - Test data: http://www.pjreddie.com.media/files/mnist_train.csv\n",
    " - 입력, 정답 데이터 동시 존재\n",
    "   \n",
    "   \n",
    "2. Framework load\n",
    " - Keras(mnist.load_data(), TensorFlow ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8217aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train_data, t_train_data), (x_test_data, t_test_data)= mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98896d",
   "metadata": {},
   "source": [
    "# MNIST 구조 (Data Frame)\n",
    "1. mnist_train.csv : 학습에 이용될 수 있는 정답 데이터 6만개 존재\n",
    " - 1개의 데이터에 785개의 숫자가 (,)로 구분되어있음\n",
    " - 1개의 정답 숫자과 정답 숫자를 필기한 숫자 이미지를 나타내는 784개의 숫자로 구성됨\n",
    "    \n",
    "    \n",
    "2. mnist_test.csv : 학습 후 딥러닝 아키텍처가 얼마나 잘 동작하는지 테스트할 수 있는 데이터 1만개 존재\n",
    " - 정답이 포함된 785개의 숫자로 되어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d276a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_csv= pd.read_csv(\"MNIST_dataset/mnist_train.csv\")\n",
    "mnist_test_csv= pd.read_csv(\"MNIST_dataset/mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99c49e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.608</th>\n",
       "      <th>0.609</th>\n",
       "      <th>0.610</th>\n",
       "      <th>0.611</th>\n",
       "      <th>0.612</th>\n",
       "      <th>0.613</th>\n",
       "      <th>0.614</th>\n",
       "      <th>0.615</th>\n",
       "      <th>0.616</th>\n",
       "      <th>0.617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   5  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.608  0.609  0.610  \\\n",
       "0  0  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "1  4  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "2  1  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "3  9  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "4  2  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "\n",
       "   0.611  0.612  0.613  0.614  0.615  0.616  0.617  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30b6b004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.658</th>\n",
       "      <th>0.659</th>\n",
       "      <th>0.660</th>\n",
       "      <th>0.661</th>\n",
       "      <th>0.662</th>\n",
       "      <th>0.663</th>\n",
       "      <th>0.664</th>\n",
       "      <th>0.665</th>\n",
       "      <th>0.666</th>\n",
       "      <th>0.667</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   7  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.658  0.659  0.660  \\\n",
       "0  2  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "1  1  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "2  0  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "3  4  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "4  1  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "\n",
       "   0.661  0.662  0.663  0.664  0.665  0.666  0.667  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772cb670",
   "metadata": {},
   "source": [
    "# MNIST 구조(Loadtxt)\n",
    "1. train_data 행렬\n",
    " - 1개의 행 (row) : 레코드\n",
    "     1. 1개의 레코드는 785개의 열(column)으로 구성\n",
    "     2. 1 열(column)에는 정답데이터가 있음\n",
    "     3. 2 열(column)부터 마지막 열(column)까지는 정답을 나타내는 이미지의 color를 나타내는 숫자 값들 784개가 연속으로 있음 \n",
    "     4. 8bit 흑백 이미지의 화소값(pixel value, gray level)을 이용해 0~255사이의 값을 가짐 (0일수록 검은색)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8f2ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬로 표현\n",
    "train_data=np.loadtxt(\"MNIST_dataset/mnist_train.csv\", delimiter=',', dtype=np.float32)\n",
    "test_data=np.loadtxt(\"MNIST_dataset/mnist_test.csv\", delimiter=',', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f8cdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 785), (10000, 785))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bee9251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [6., 0., 0., ..., 0., 0., 0.],\n",
       "       [8., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4470e01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지로 표현\n",
    "# 1번째 행의 2열부터 마지막 열까지의 784개의 데이터를 28*28행렬로 나타냄\n",
    "# 이미지맵 imshow()의 camp 속성으로 흑백 이미지 출력\n",
    "\n",
    "img=train_data[0][1:].reshape(28,28)\n",
    "\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9747c2",
   "metadata": {},
   "source": [
    "# 딥러닝 아키텍처\n",
    "  \n",
    "  \n",
    "## 노드 개수 설정\n",
    "  \n",
    "1. 입력층\n",
    " - 입력층의 노드를 입력 데이터 개수와 일치하도록 (784개) 설정\n",
    " - 1개의 레코드(행): 785개의 열을 가지지만, 정답 데이터(1열)을 제외 \n",
    "  \n",
    "  \n",
    "2. 입력층-은닉층 W2, 은닉층-출력층 W3\n",
    " - 별도의 규칙 없이 임의로 100개 설정\n",
    " - 노드 개수가 많아질때 학습 속도 느려짐\n",
    "  \n",
    "  \n",
    "3. 출력층 : **one-hot encoding**\n",
    " - 10개 설정\n",
    " - 정답이 0~9 중 하나의 숫자 이므로 10개의 원소를 갖는 list 만듬\n",
    " - list에서 최대값을 가지는 index를 정답으로 판단할 수 있도록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330aeb8",
   "metadata": {},
   "source": [
    "## 신경망 MNIST 인식 클래스\n",
    "\n",
    "**1. externel function**  \n",
    "\n",
    " - def sigmoid(x) : *# 0 또는 1을 출력하기 위한 sigmoid 함수*\n",
    "  \n",
    " - def numerical_derivate(f,x) : *# 수치미분 함수*\n",
    " \n",
    "**2. NeuralNetwork Class**\n",
    "  \n",
    "  - class NeuralNetwork:   \n",
    "      - def  __init__(self, input_nodes, hidden_nodes, output_nodes) : *# 입력층, 은닉층, 출력층 개수를 입력받아 가중치, 바이어스, 학습율 초기화*\n",
    "      - def feed_forward(self), def loss_val(self) :  *# 손실함수값 계산, 출력담당*\n",
    "      - def train(self, train_data)  : *# 수치미분으로 가중치,바이어스 업데이트*\n",
    "      - def predict(self,input_data) : *# 입력 데이터에 대한 미래 값 예측*\n",
    "      - def accuracy(self, test_data): *# 정확도 측정*\n",
    "  \n",
    "**3. Usage**\n",
    " - nn= NeuralNetwork(784,100,10)\n",
    "   \n",
    " - for step in range(30001):   *# 6만개 트레이닝 데이터 중 50%데이터로 학습진행*\n",
    "     index= np.random.randint(0,59999)  *# 시간문제로 6만개 데이터 중 3만개 랜덤하게 선택*\n",
    "     nn.train(train_data [index]) *# 학습진행*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02d812a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치미분 함수\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee73a1e",
   "metadata": {},
   "source": [
    "## 딥러닝 개요\n",
    "0. 뉴런\n",
    " - 인간의 뇌는 뉴런이라고 불리는 세포의 집합체\n",
    " - 뉴런은 어떤 신호를 받고 변조하고 다시 다음으로 전달함\n",
    " - 시냅스에서 뉴런이 신호를 받을 때 분비된 화학물질의 양과 분비되는 시간의 곱(w)으로 나타낼 수 있음\n",
    " - 이 값이 특정 임계점을 넘어야(활성함수) 다음 시냅스로 연결될 수 있음\n",
    " - 활성함수 값이 임계점을 넘으면 1을 리턴, 아니면 0 리턴\n",
    "     - $f(\\sum_{i=1}^{n}x_{i}w_{i}+b)$\n",
    "     \n",
    "1. 퍼셉트론 (perceptron = perception+neuron)\n",
    "   - 퍼셉트론: 인공신경망의 구성요소(unit) 다수의 값을 입력받아 하나의 값으로 출력하는 알고리즘\n",
    "   - 이진 분류 모델을 학습하기 위한 지도학습의 알고리즘\n",
    "   - 동작과정 \n",
    "     1. 다른 값 x를 입력받고, 입력된 값마다 가중치를 곱하고 편항(바이어스)를 더하여 각 값을 합산해 가중합을 도출함\n",
    "     2. 이 가중합의 크기를 임계값(0)과 비교(활성화 함수를 통해)해 최종출력(0 or 1)값 결정\n",
    "    - 단층 퍼셉트론: 입력값에 따른 출력값을 구분 짓는 직선을 1개 그림\n",
    "      - 은닉층 없이 입력층과 출력층만 있음 : 출력값과 실제를 비교해 오차가 최소가 되도록 업데이트 하면 됨\n",
    "      - 비선형 활성함수 1개-> 계단함수(입력이 0을 넘으면 1을 출력 그외는 0)를 보통 사용한다고 함(이외에 다층은 시그모이드, 렐루 등)\n",
    "      \n",
    "      - 활성함수를 비선형 함수로 보통 쓰는이유는 선형함수를 사용했을 때 신경망의 층을 깊게 하는 의미가 없어짐(시그모이드, 계단함수 둘다 비선형)\n",
    "      - 직선 선형함수 f(f(f(f(a)))) 는 결과값의 거듭제곱꼴처럼 돼서 \n",
    "       \n",
    "      - and,or 게이트는 선형방정식이므로 단층퍼셉트론 가능\n",
    "      - 굳이 은닉층이 없어도 된다는 뜻\n",
    "      - xor게이트 표현하지 못함 (입력값이 서로 다를때만 1을 가지므로)\n",
    "      - 비선형 방정식으로써 50%의 정확도밖에 못냄\n",
    "      - 1969년 Marvin Minsky가 증명해냈는데 MLP로 어떻게 하는지 구현하지 못해 신경망 암흑기 옴\n",
    "      - 1984년 Geoffrey Hinton이 역전파를 발표함\n",
    "      \n",
    "    - 다층 퍼셉트론 (Multi-Layer Perception, MLP)\n",
    "       - 입력층과 출력층 사이에 여러개 은닉층이 있는 인공신경망, 출력층도 여러개일 수 있음\n",
    "       - 최종 출력값과 실제값의 오차가 최소화 되도록 가중치와 바이어스를 계산해 결정하는 것\n",
    "   - 심층 신경망를 학습하기 위해 고안된 알고리즘 : 딥러닝\n",
    "   - 은닉층이 존재하는 다층 퍼셉토론에서 입력층이 전달되는 값이 은닉층의 모든 노드로 전달(하나의 단층 퍼셉트론)\n",
    "     - 은닉층의 각 노드는 퍼셉트론의 활성함수\n",
    "     - 은닉층의 모든 노드 출력값도 출력층의 모든 노드로 전달\n",
    "     - => 순전파\n",
    "     1. 각 노드의 가중치와 바이어스를 어떻게 업데이트?\n",
    "     2. MLP에서 각 노드, 레이어가 가지고 있는 변수들은 제각각인데 얼만큼 변경하는지 어떻게 아는가? (은닉층의 출력값에 대한 기준을 정의할 수 없음)\n",
    "       \n",
    "       \n",
    "   - 역전파: 새로운 가중치로 다시 학습화는 가정(오차가 0이 될때까지)\n",
    "       - input, output 값을 알고 있는 상태에서 신경망을 학습시키는 지도학습의 개념을 사용한 퍼셉트론에서 이어짐\n",
    "        - 출력층에서 발생하는 오차값을 이용해 은닉층으로 역전파 시켜 은닉층에서 발생하는 오차값에 따라 은닉층의 가중치를 업데이트 함\n",
    "        - 이 강의에서는 활성함수를 sigmoid로 결정\n",
    "        - 체인룰(chain rule) => 시그모이드 함수를 미분할때 체인룰을 적용하여 빠른 속도의 가중치를 얻을 수 있음\n",
    "        - 역전파를 실행할 때 가중치를 결정하는 방법은 경사하강법(강의에서는 수치미분이라고 표현함)을 사용=> 오래걸림\n",
    "        - 출력층에서 한번 미분한 후 결과를 뒤에 노드에 전달하면서 재사용\n",
    "        - 히든층의 활성도(출력값 y)를 바꿀 때 얼마나 빨리 오차가 변하는지(오차변화도 함수) 계산가능 -> 가중치 바꿀 때 오차가 얼마나 빨리 변하는지\n",
    "       - 대신 모든 점에서 연속이며 미분 가능하므로 신경망이 극단적인 형태가 아니라 데이터를 섬세하게 분류할 수 있도록 도와줌\n",
    "        \n",
    "      \n",
    "\n",
    "## Xavier(사비에르)/He  방법\n",
    "  \n",
    " 1. 가중치 초기화의 중요성(시그모이드를 쓸때)\n",
    " - 은닉층이 있는 퍼셉트론에서 왜 계단함수를 안쓰고 시그모이드를 쓰냐\n",
    "     - 계단형식 함수를 미분 가능하도록 곡선화 시키고이상치가 들어와도 0,1에 매끄럽게 수렴해서 괜찮음\n",
    "     \n",
    " - 단점\n",
    "     - 시그모이드를 쓰면 로지스틱 회귀를 겹겹히 쌓아놓은 구조로 돼서 다층 퍼셉트론이라고 하기 애매하다는 의견도 있음\n",
    "     1. 은닉층이 깊어질수록 가중치가 0으로 수렴하여 정확성이 감소함\n",
    "         - 이는 2개이상의 은닉층을 가진 다층 퍼셉트론인 심층신경망(DNN)일때 말함\n",
    "         - 역전파에서 기울기를 계산할 때 시그모이드 함수의 미분꼴을 갖게 되고, 깊이가 깊어질수록 시그모이드의 미분 인자가 하나씩 추가되므로 최종 계산 결과(0,1)인 기울기 값이 0에 가까워져버림 -> 앞층으로 역전파가 안됨\n",
    "         - 시그모이드 함수의 0,1 값의 기울기는 0.000x 이기 때문(대칭분포)\n",
    "         - 대표적인 곡선 함수 시그모이드는 역전파를 할 때 기울기 소실이 발생\n",
    "     \n",
    "     2. 시그모이드 함수의 출력값이 모두 양수이므로 경사하강법시 기울기가 양수, 음수가 돼 기울기 업데이트가 지그재그로 변동하면 학습효율성을 감소시켜 매우 오래걸림\n",
    "\n",
    " - 은닉층에서 시그모이드 사용(하고싶으면 하이퍼볼릭 탄젠트쓰기)하지 않기, 이진분류 하고싶을 때 출력에서 사용하기\n",
    " - => Relu 알고리즘 사용 (x값이 0이하면 0을 출력, 0 이상이면 비례함수를 적용해 max(0,x)함수사용해 그 값을 그대로 반환\n",
    " - 출력층에는 활성화함수를 쓰지 않거나, 소프트맥스 등 다른 함수를 쓸수있음\n",
    "   \n",
    "   \n",
    " **시그모이드를 잘 쓰기 위해 가중치를 초기화 하는 방법** \n",
    "   \n",
    "   \n",
    "  1. 0을 써보자\n",
    "   - 뉴런이 트레이닝 중 동일한 특성을 학습하게 되어 두번째 뉴런에도 똑같은 값이 전달되고(순전파할때) , 역전파에서 모든 가중치 값이 똑같아짐\n",
    "   - 대칭적인 가중치가 되어 두 노드가 같은 일을 하게 되는 중복성이 발생\n",
    "   - 중복성이 발생되면 은닉층을 쓰는 이유가 없어짐..  \n",
    "     \n",
    "     \n",
    "  2. 무작위로 해보자(강의에서 씀) \n",
    "   - 분포도를 확인해보면 활성화 값이 0과 1에 치우쳐져 분포됨\n",
    "   - 시그모이드 함수는 출력이 0,1에 가까워지면 미분값이 0이되어버려\n",
    "   - 역전파때 기울기가 점점 작아지다가 아예 사라짐!!(Gradient Vanshing)\n",
    "     \n",
    "     \n",
    "  3. 가우시안 분포를 따르는 값에 따라 랜덤하게 초기화 해보자 N(0,0.01)\n",
    "    - 표준편차를 크게 할 때 (1) 시그모이드 값인 0,1의 기울기인 0으로 수렴하여 기울기가 계속 없어지기 때문 => 역전시 기울기가 0\n",
    "   -  작은 표준편차를 할 때 (0.001) 0.5 중심으로 모여있어 가중치 손실 덜하지만 출력값이 모두 동일하면 역전파할때 가중치를 동일하게 계산하게 됨  \n",
    "     \n",
    "     \n",
    " 2. Weight decay : 가중치 감소기법 정리\n",
    " > - 가능한한 작은 값이며 겹치지 않은 가중치를 사용\n",
    " > - 각 층의 활성화 함수를 거쳐 나온 값들은 적당히 골고루 분포되어있어야 함\n",
    " > - 이전 레이어의 활성함수 값과 다음 레이어의 활성 함수 평균, 표준편차가 일정해야 레이어를 깊고 무한하게 쌓을 수 있음\n",
    "  - **np.random.randn 쓰면 w 평균값 0, 표준편차가 1인 정규분포를 따르도록 초기화+ 작은상수 곱합**\n",
    "       - 작은 상수 곱하는 이유는 w가 크면 그 전 시그모이드 출력값 a는 작아지고, 거기에 가중치 곱한 w는 엄청 커져서.. => 역전파하면 기울기가 0이됨  \n",
    "         \n",
    "         \n",
    " **3. Xavier/He**\n",
    "  - 적당히 골고루 분포되게 하는법\n",
    "  \n",
    "  1. Xavier intialization\n",
    "   - 평균을 0으로 유지하되, 분산값(표준편차)을 조정한다\n",
    "   - 주로 시그모이드, 하이퍼 탄젠트와 같은 s자형 곡선을 가지는 활성화 함수에서 쓰임\n",
    "   - 뉴런의 개수가 많아지면 그만큼 적은 값의 분포를 활용하여 가중치가 더 좁게 펴져 레이어가 깊어질수록 데이터가 적당히 넓게 퍼지게 됨\n",
    "   - 뉴런 개수에 따라 가중치가 초기화되므로 고정된 표준편차를 쓰는 것 보다 이상값에 영향을 덜 받는 로버스트한 통계량을 가짐(다음 층의 노드 수도 사용)\n",
    "   - 단순히 작게하는게 아니라 표준 정규분포를 입력 개수의 표준편차로 나눔\n",
    "   - 표준편차= 분산의 제곱근으로 평균으로부터 원래 데이터에 대한 오차범위 근사값\n",
    "   > w = np.random.randn(n_input,n_output)/sqrt(n_input)\n",
    "  - 렐루에서는 가중치초기화로 사비에르를 쓰면 출력값이 0으로 수렴하므로 안됨\n",
    "  - Tensorflow keras에서 디폴트로 제공하는 가중치 초기화 방법\n",
    "      - Xavier uniform(파라미터 상한,하한값 정해 그 안에서 초기화)\n",
    "   2. He intialization \n",
    "    - Relu와 같이 쓰임\n",
    "    - 표준 정규분포로 초기화 된 가중치를 2/입력개수 제곱근으로 나눔\n",
    "    > w= np.random.randn(n_input,n_output)/sqrt(2/n_input)\n",
    "\n",
    "## 데이터 전처리\n",
    "### 입력데이터 정규화(Nomalization)\n",
    "   1. 일반적인 정규화 방법\n",
    "    - 딥러닝에서 입력 데이터의 상대적 크기에 대한 영향을 줄이기 위해 MinMax공식을 이용해 모든 데이터 범위를 0~1사이의 값으로 변화 시킴\n",
    "      \n",
    "      \n",
    "   - $data_{new}=\\frac{data-Min}{Max-Min}$\n",
    "       \n",
    "       \n",
    "   - 데이터의 최대값(255*0.99)로 나누어줌\n",
    "   - 모든 입력값을 0~1사이 값으로 정규화함\n",
    "       - data = (input_data[index, :] / 255.0 * 0.99) + 0.01\n",
    "       \n",
    "   2. normalize (정규화)\n",
    "     - 원핫 인코딩을 위한 10개의 노드 0.01 초기화 \n",
    "       - self.target_data=np.zeros(output_nodes)+0.01\n",
    "     - 정답을 나타내는 인덱스의 가장 큰 값인 0.99로 초기화\n",
    "     - 정답: 5일 경우 출력노드의 5번째 인덱스에 0.99를 집어넣음 \n",
    "       - self.target_data[int(training_data[0])] = 0.99\n",
    "     - 입력 데이터가 0~255이므로 이를 그대로 사용할 경우 손실함수 cross_entropy log부분에서 오버플로우가 생길 가능성 있음\n",
    "       \n",
    "    \n",
    "       \n",
    "### 미래값 예측에서의 원핫인코딩\n",
    "1. 원핫인코딩 (One-Hot Encoding)\n",
    " - 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어 인덱스에 1, 나머지 인덱스에는 0 부여\n",
    " - 정답이 되는 인덱스가 가장 큰값을 가지므로 이를 1로 만들어줌  \n",
    " \n",
    "2. np.argmax(y)\n",
    " - 가장 큰 값을 가지는 원소의 인덱스를 반환\n",
    " - 큰 원소가 여러개 있을 경우 가장 앞에 있는 인덱스 반환\n",
    "   \n",
    "3. Tensorflow 프레임워크, keras 라이브러리 \n",
    " - tf.keras.utils.to_categorical(train, num_classes=10)\n",
    " - 정답데이터가 0~9까지이므로 10개 설정\n",
    " \n",
    "## 정확도 측정 함수\n",
    "1. accuracy()\n",
    " - 만든 딥러닝 아키텍처가 얼마나 정확하게 mnist를 구별했는지 판단\n",
    "   1. test_data를 입력받아 1열에 있는 정답을 분리함\n",
    "   2. test_data 안에 있는 정답 이외의 784개의 데이터를 0~1사이 값 갖도록 정규화\n",
    "   3. predict() 호출 후 실제 정답과 예측한 정답이 맞는지 판단\n",
    "   4. 맞으면 match_list에 넣음, 틀리면 not_match_list에 넣음\n",
    "   5. test_data의 길이로 macth_list의 길이를 나누고 %화 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dc36dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST_Test Class\n",
    "\n",
    "class MNIST_Test:\n",
    "    \n",
    "    # 생성자\n",
    "    # xdata, tdata => numpy.array(...)\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes # 784개\n",
    "        self.hidden_nodes = hidden_nodes # 100개\n",
    "        self.output_nodes = output_nodes # 10개\n",
    "        \n",
    "        # 은닉층 가중치  W2  Xavier/He 방법으로 self.W2 가중치 초기화\n",
    "        self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes) / np.sqrt(self.input_nodes/2)\n",
    "        self.b2 = np.random.rand(self.hidden_nodes)      \n",
    "        \n",
    "        # 출력층 가중치는 W3  Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        self.W3 = np.random.randn(self.hidden_nodes, self.output_nodes) / np.sqrt(self.hidden_nodes/2)\n",
    "        self.b3 = np.random.rand(self.output_nodes)      \n",
    "        \n",
    "        # 2층 hidden layer unit \n",
    "        # 가중치 W, 바이어스 b 초기화\n",
    "        #self.W2 = np.random.rand(input_nodes, hidden_nodes)  \n",
    "        #self.b2 = np.random.rand(hidden_nodes)\n",
    "        \n",
    "        # 3층 output layer unit : 1 개 \n",
    "        #self.W3 = np.random.rand(hidden_nodes,output_nodes)\n",
    "        #self.b3 = np.random.rand(output_nodes)\n",
    "                        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        print(\"MNIST_Test object is created !!!\")\n",
    "        \n",
    "    # 손실함수\n",
    "    def feed_forward(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z1 = np.dot(self.input_data, self.W2) + self.b2\n",
    "        y1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(y1, self.W3) + self.b3\n",
    "        y = sigmoid(z2)\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    # obtain W and b\n",
    "    def get_W_b(self):\n",
    "        \n",
    "        return self.W2,  self.b2, self.W3, self.b3\n",
    "    \n",
    "    # 손실 값 계산 후 외부 출력용으로 사용됨\n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z1 = np.dot(self.input_data, self.W2) + self.b2\n",
    "        y1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(y1, self.W3) + self.b3\n",
    "        y = sigmoid(z2)\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    # query, 즉 미래 값 예측 함수\n",
    "    def predict(self, input_data):    \n",
    "        \n",
    "        z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "    \n",
    "        # MNIST 경우는 one-hot encoding 을 적용하기 때문에\n",
    "        # 0 또는 1 이 아닌 argmax() 를 통해 최대 인덱스를 넘겨주어야 함\n",
    "        predicted_num = np.argmax(y)\n",
    "    \n",
    "        return predicted_num\n",
    "\n",
    "    # 정확도 측정함수\n",
    "    def accuracy(self, input_data, target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        # list which contains (index, label, prediction) value\n",
    "        index_label_prediction_list = []\n",
    "        \n",
    "        # temp list which contains label and prediction in sequence\n",
    "        temp_list = []\n",
    "        \n",
    "        for index in range(len(input_data)):\n",
    "                        \n",
    "            label = int(target_data[index])\n",
    "                        \n",
    "            # normalize\n",
    "            data = (input_data[index, :] / 255.0 * 0.99) + 0.01\n",
    "      \n",
    "            predicted_num = self.predict(data)\n",
    "        \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "                \n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "                temp_list.append(index)\n",
    "                temp_list.append(label)\n",
    "                temp_list.append(predicted_num)\n",
    "                \n",
    "                index_label_prediction_list.append(temp_list)\n",
    "                \n",
    "                temp_list = []\n",
    "                \n",
    "        print(\"Current Accuracy = \", len(matched_list)/(len(input_data)) )\n",
    "        \n",
    "        return matched_list, not_matched_list, index_label_prediction_list\n",
    "    \n",
    "        \n",
    "    # 수치미분을 이용하여 손실함수가 최소가 될때 까지 학습하는 함수\n",
    "    def train(self, input_data, target_data):\n",
    "     \n",
    "        self.input_data = input_data\n",
    "        self.target_data = target_data\n",
    "        \n",
    "        f = lambda x : self.feed_forward()\n",
    "        \n",
    "        self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\n",
    "    \n",
    "        self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\n",
    "        \n",
    "        self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\n",
    "    \n",
    "        self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1803ba89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_Test object is created !!!\n",
      "Neural Network Learning using Numerical Derivative...\n",
      "epochs =  0 , index =  0 , loss value =  10.575341940636896\n",
      "epochs =  0 , index =  200 , loss value =  3.18859610487451\n",
      "epochs =  0 , index =  400 , loss value =  2.8590640943758125\n",
      "epochs =  0 , index =  600 , loss value =  2.942886005793964\n",
      "epochs =  0 , index =  800 , loss value =  2.8419300812591244\n",
      "epochs =  0 , index =  1000 , loss value =  2.221285705544171\n",
      "epochs =  0 , index =  1200 , loss value =  1.9387274464153454\n",
      "epochs =  0 , index =  1400 , loss value =  1.7034484901501188\n",
      "epochs =  0 , index =  1600 , loss value =  2.9203411100595704\n",
      "epochs =  0 , index =  1800 , loss value =  2.491437571355741\n",
      "epochs =  0 , index =  2000 , loss value =  3.4487458726181304\n",
      "epochs =  0 , index =  2200 , loss value =  1.9846106156130507\n",
      "epochs =  0 , index =  2400 , loss value =  2.023065590998051\n",
      "epochs =  0 , index =  2600 , loss value =  2.480488851902815\n",
      "epochs =  0 , index =  2800 , loss value =  2.055209028742412\n",
      "epochs =  0 , index =  3000 , loss value =  3.0532714024008096\n",
      "epochs =  0 , index =  3200 , loss value =  2.246445686842382\n",
      "epochs =  0 , index =  3400 , loss value =  1.1546898313718503\n",
      "epochs =  0 , index =  3600 , loss value =  2.2142542580856257\n",
      "epochs =  0 , index =  3800 , loss value =  1.148673386855398\n",
      "epochs =  0 , index =  4000 , loss value =  1.1408153571240356\n",
      "epochs =  0 , index =  4200 , loss value =  1.5735594921465696\n",
      "epochs =  0 , index =  4400 , loss value =  1.1617518528778785\n",
      "epochs =  0 , index =  4600 , loss value =  2.5537839173696475\n",
      "epochs =  0 , index =  4800 , loss value =  2.1090753653813077\n",
      "epochs =  0 , index =  5000 , loss value =  1.0770149279696946\n",
      "epochs =  0 , index =  5200 , loss value =  1.9971218519138425\n",
      "epochs =  0 , index =  5400 , loss value =  2.0646597192547445\n",
      "epochs =  0 , index =  5600 , loss value =  1.6119606402510802\n",
      "epochs =  0 , index =  5800 , loss value =  3.242406261024349\n",
      "epochs =  0 , index =  6000 , loss value =  0.7165279506594546\n",
      "epochs =  0 , index =  6200 , loss value =  2.0006614123830064\n",
      "epochs =  0 , index =  6400 , loss value =  0.9248080452286074\n",
      "epochs =  0 , index =  6600 , loss value =  2.08018301807646\n",
      "epochs =  0 , index =  6800 , loss value =  0.926519222668448\n",
      "epochs =  0 , index =  7000 , loss value =  2.0003990171130717\n",
      "epochs =  0 , index =  7200 , loss value =  1.8136180203295562\n",
      "epochs =  0 , index =  7400 , loss value =  1.5927338524087955\n",
      "epochs =  0 , index =  7600 , loss value =  1.4779705880479947\n",
      "epochs =  0 , index =  7800 , loss value =  1.3748458049251575\n",
      "epochs =  0 , index =  8000 , loss value =  0.6431277953527976\n",
      "epochs =  0 , index =  8200 , loss value =  5.991967510520008\n",
      "epochs =  0 , index =  8400 , loss value =  1.2693624935421874\n",
      "epochs =  0 , index =  8600 , loss value =  2.610294515177724\n",
      "epochs =  0 , index =  8800 , loss value =  0.8218572573996306\n",
      "epochs =  0 , index =  9000 , loss value =  1.2515356565607385\n",
      "epochs =  0 , index =  9200 , loss value =  0.7675037074869433\n",
      "epochs =  0 , index =  9400 , loss value =  0.8519452039617745\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m target_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(o_nodes) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.01\u001b[39m    \n\u001b[0;32m     26\u001b[0m target_data[\u001b[38;5;28mint\u001b[39m(train_data[index, \u001b[38;5;241m0\u001b[39m])] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.99\u001b[39m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (index \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs = \u001b[39m\u001b[38;5;124m\"\u001b[39m, step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, index = \u001b[39m\u001b[38;5;124m\"\u001b[39m, index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, loss value = \u001b[39m\u001b[38;5;124m\"\u001b[39m, obj\u001b[38;5;241m.\u001b[39mloss_val())\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mMNIST_Test.train\u001b[1;34m(self, input_data, target_data)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_data \u001b[38;5;241m=\u001b[39m target_data\n\u001b[0;32m    129\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward()\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW2 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m \u001b[43mnumerical_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m numerical_derivative(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW3 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m numerical_derivative(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW3)\n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mnumerical_derivative\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m fx1 \u001b[38;5;241m=\u001b[39m f(x) \u001b[38;5;66;03m# f(x+delta_x)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m x[idx] \u001b[38;5;241m=\u001b[39m tmp_val \u001b[38;5;241m-\u001b[39m delta_x \n\u001b[1;32m---> 16\u001b[0m fx2 \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# f(x-delta_x)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m grad[idx] \u001b[38;5;241m=\u001b[39m (fx1 \u001b[38;5;241m-\u001b[39m fx2) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mdelta_x)\n\u001b[0;32m     19\u001b[0m x[idx] \u001b[38;5;241m=\u001b[39m tmp_val \n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mMNIST_Test.train.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_data \u001b[38;5;241m=\u001b[39m input_data\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_data \u001b[38;5;241m=\u001b[39m target_data\n\u001b[1;32m--> 129\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW2 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m numerical_derivative(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW2)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m numerical_derivative(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2)\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mMNIST_Test.feed_forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     38\u001b[0m     delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-7\u001b[39m    \u001b[38;5;66;03m# log 무한대 발산 방지\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     z1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2\n\u001b[0;32m     41\u001b[0m     y1 \u001b[38;5;241m=\u001b[39m sigmoid(z1)\n\u001b[0;32m     43\u001b[0m     z2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(y1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW3) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb3\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#hyper-parameter\n",
    "i_nodes = train_data.shape[1] - 1    # input nodes 개수 784개\n",
    "h1_nodes = 30  # hidden nodes 개수. Test 8->30\n",
    "o_nodes = 10    # output nodes 개수\n",
    "lr = 1e-2      # learning rate\n",
    "epochs = 1   # 반복횟수 역전파를 한번 돌림\n",
    "\n",
    "# 손실함수 값을 저장할 list 생성\n",
    "loss_val_list = []\n",
    "\n",
    "# MNIST_Test 객체 생성\n",
    "obj = MNIST_Test(i_nodes, h1_nodes, o_nodes, lr)\n",
    "\n",
    "print(\"Neural Network Learning using Numerical Derivative...\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in range(epochs):\n",
    "    \n",
    "    for index in range(len(train_data)):    \n",
    "                \n",
    "        # input_data, target_data normalize    \n",
    "        input_data = ((train_data[index, 1:] / 255.0) * 0.99) + 0.01\n",
    "        \n",
    "        target_data = np.zeros(o_nodes) + 0.01    \n",
    "        target_data[int(train_data[index, 0])] = 0.99\n",
    "        \n",
    "        obj.train(input_data, target_data)\n",
    "        \n",
    "        if (index % 200 == 0):\n",
    "            print(\"epochs = \", step, \", index = \", index, \", loss value = \", obj.loss_val())\n",
    "            \n",
    "        # 손실함수 값 저장\n",
    "        loss_val_list.append(obj.loss_val())        \n",
    "\n",
    "end_time = datetime.now()\n",
    "        \n",
    "print(\"\")\n",
    "print(\"Elapsed Time => \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63715ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.loadtxt('./mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "print(\"test_data.shape = \", test_data.shape)\n",
    "\n",
    "test_input_data = test_data[ :, 1: ]\n",
    "test_target_data = test_data[ :, 0 ]\n",
    "\n",
    "(true_list_1, false_list_1, index_label_prediction_list) = obj.accuracy(test_input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 추세 확인\n",
    "x_data_list = [ index for index in range(len(training_data)) ]\n",
    "Y_DATA_LIST = []\n",
    "\n",
    "for index in range(0, len(loss_val_list), 500):\n",
    "    Y_DATA_LIST.append(loss_val_list[index])\n",
    "    \n",
    "plt.title('MNIST Loss Value Trend')\n",
    "plt.xlabel('data index ( X 500)')\n",
    "plt.ylabel('loss value')\n",
    "plt.grid()\n",
    "#plt.ylim(2.1, 7.1)\n",
    "#plt.plot(x_data_list, loss_val_list, color='b')\n",
    "plt.plot(Y_DATA_LIST, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4007c7",
   "metadata": {},
   "source": [
    "# 정확도 높이기\n",
    "> 시간을 줄이기 위해 오차 역전파로 해결\n",
    "1. 여러개의 은닉층 두기\n",
    "2. 합성곱 신경망(CNN) 활용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1bfbef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
